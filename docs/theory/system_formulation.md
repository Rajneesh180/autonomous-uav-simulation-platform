# System Formulation

This section formalizes the UAV simulation as a discrete-time dynamical system.

The formulation is phase-consistent and extends naturally to learning-based control (Phase-5).

---

# 1. System State

At time step t, the complete system state is defined as:

S(t) = { P_u(t), B(t), N(t), O(t), R(t) }

Where:

P_u(t) âˆˆ â„Â²      â†’ UAV position  
B(t) âˆˆ â„âº        â†’ Remaining battery energy  
N(t)             â†’ Active node set  
O(t)             â†’ Obstacle set  
R(t)             â†’ Risk field  

---

# 2. State Transition Model

System evolution is governed by:

S(t+1) = F(S(t), a(t), Î¾(t))

Where:

a(t)     â†’ Control action selected by planner  
Î¾(t)     â†’ Environmental stochastic events (node churn, obstacle motion)

The transition function F consists of:

1. UAV motion update  
2. Energy update  
3. Obstacle motion update  
4. Node set update  
5. Risk field update  

---

# 3. UAV Motion Model

Given control action a(t):

P_u(t+1) = P_u(t) + Î”t Â· V_u(t)

Where velocity V_u(t) is determined by selected steering primitive.

Movement is bounded by:

â€–V_u(t)â€– â‰¤ V_max

---

# 4. Energy Dynamics

Energy consumption for movement:

E_move(t) = c_e Â· d(t) Â· Ï(P_u(t), t)

Where:

c_e       â†’ Energy per meter  
d(t)      â†’ Distance traveled at step t  
Ï(p, t)   â†’ Risk multiplier  

Battery update:

B(t+1) = B(t) - E_move(t) - E_hover(t)

Mission terminates if:

B(t) â‰¤ B_min

---

# 5. Obstacle Dynamics

Each obstacle:

o_j(t) = (xâ‚, yâ‚, xâ‚‚, yâ‚‚, v_x, v_y)

Linear motion model:

xâ‚(t+1) = xâ‚(t) + v_x  
xâ‚‚(t+1) = xâ‚‚(t) + v_x  
yâ‚(t+1) = yâ‚(t) + v_y  
yâ‚‚(t+1) = yâ‚‚(t) + v_y  

Velocity magnitude scaled by hostility profile.

---

# 6. Node Set Evolution

Node set evolves via:

N(t+1) = N(t)
         âˆª Spawn(t)
         \ Remove(t)

Spawn(t) triggered by interval condition.

Remove(t) triggered probabilistically with minimum floor constraint.

---

# 7. Risk Field Evolution

Risk multiplier:

Ï(p, t) = Ï_base(p) + Î´Ï(t)

Where Î´Ï(t) may vary temporally.

Currently deterministic, extensible to stochastic.

---

# 8. Replanning Trigger Function

Replanning occurs if:

ð’¯(t) = 1

Where:

ð’¯(t) = 1 if any of:

- Node set changed
- Collision detected
- Energy risk threshold exceeded
- Path invalidated by obstacle
- Environmental condition triggered

Replanning cooldown enforces:

t - t_last_replan â‰¥ Ï„

---

# 9. Control Objective (Phase-3)

Maximize mission coverage while maintaining feasibility:

Maximize:

|Visited Nodes|

Subject to:

B(t) > B_min  
Collision avoidance  
Dynamic feasibility  

No semantic weighting yet (introduced in Phase-4).

---

# 10. Determinism & Reproducibility

Given fixed seed:

S(0) deterministic  
Î¾(t) deterministic  

Thus system trajectory is reproducible.

---

This formalization defines the simulator as a controlled stochastic dynamical system, forming the basis for semantic extension (Phase-4) and policy optimization (Phase-5).
